{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset import MaskBaseDataset\n",
    "from loss import create_criterion\n",
    "import timm\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_image(np_images, gts, preds, n=16, shuffle=False):\n",
    "    batch_size = np_images.shape[0]\n",
    "    assert n <= batch_size\n",
    "\n",
    "    choices = random.choices(range(batch_size), k=n) if shuffle else list(range(n))\n",
    "    figure = plt.figure(\n",
    "        figsize=(12, 18 + 2)\n",
    "    )  # cautions: hardcoded, 이미지 크기에 따라 figsize 를 조정해야 할 수 있습니다. T.T\n",
    "    plt.subplots_adjust(\n",
    "        top=0.8\n",
    "    )  # cautions: hardcoded, 이미지 크기에 따라 top 를 조정해야 할 수 있습니다. T.T\n",
    "    n_grid = int(np.ceil(n**0.5))\n",
    "    tasks = [\"mask\", \"gender\", \"age\"]\n",
    "    for idx, choice in enumerate(choices):\n",
    "        gt = gts[choice].item()\n",
    "        pred = preds[choice].item()\n",
    "        image = np_images[choice]\n",
    "        gt_decoded_labels = MaskBaseDataset.decode_multi_class(gt)\n",
    "        pred_decoded_labels = MaskBaseDataset.decode_multi_class(pred)\n",
    "        title = \"\\n\".join(\n",
    "            [\n",
    "                f\"{task} - gt: {gt_label}, pred: {pred_label}\"\n",
    "                for gt_label, pred_label, task in zip(\n",
    "                    gt_decoded_labels, pred_decoded_labels, tasks\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        plt.subplot(n_grid, n_grid, idx + 1, title=title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_path(path, exist_ok=False):\n",
    "    \"\"\"Automatically increment path, i.e. runs/exp --> runs/exp0, runs/exp1 etc.\n",
    "\n",
    "    Args:\n",
    "        path (str or pathlib.Path): f\"{model_dir}/{args.name}\".\n",
    "        exist_ok (bool): whether increment path (increment if False).\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -- settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# -- dataset\n",
    "dataset_module = getattr(\n",
    "    import_module(\"dataset\"), 'MaskDataset'\n",
    ")  # default: MaskBaseDataset\n",
    "dataset = dataset_module(\n",
    "    data_dir='../../../Data/train/images/',\n",
    ")\n",
    "num_classes = dataset.num_classes  # 18\n",
    "\n",
    "# -- augmentation\n",
    "transform_module = getattr(\n",
    "    import_module(\"dataset\"), 'BaseAugmentation'\n",
    ")  # default: BaseAugmentation\n",
    "transform = transform_module(\n",
    "    resize=(240,240),\n",
    "    mean=dataset.mean,\n",
    "    std=dataset.std,\n",
    ")\n",
    "dataset.set_transform(transform)\n",
    "\n",
    "# -- data_loader\n",
    "train_set, val_set = dataset.split_dataset()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=64,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=True,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=1000,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1367,  0.2856,  0.3849,  ...,  0.8151,  0.6496,  0.4014],\n",
       "          [ 0.1367,  0.3021,  0.3683,  ...,  0.8151,  0.7820,  0.4511],\n",
       "          [ 0.1698,  0.3518,  0.3849,  ...,  1.1460,  0.8813,  0.3683],\n",
       "          ...,\n",
       "          [-1.1209, -1.1374, -1.0878,  ..., -1.6669, -1.4187, -0.6576],\n",
       "          [-0.7238, -0.7734, -0.9720,  ..., -1.6504, -1.6338, -0.8065],\n",
       "          [-0.8727, -1.1043, -1.3691,  ..., -1.6835, -1.6338, -0.7899]],\n",
       " \n",
       "         [[-0.3893, -0.2464, -0.1670,  ...,  0.4204,  0.3569,  0.1664],\n",
       "          [-0.3575, -0.2147, -0.1670,  ...,  0.5157,  0.5792,  0.3093],\n",
       "          [-0.2940, -0.1353, -0.1194,  ...,  0.9602,  0.8173,  0.3569],\n",
       "          ...,\n",
       "          [-1.0402, -1.0561, -1.0085,  ..., -1.5483, -1.2784, -0.5481],\n",
       "          [-0.6592, -0.7068, -0.8974,  ..., -1.5324, -1.5007, -0.6910],\n",
       "          [-0.8021, -1.0244, -1.2784,  ..., -1.5642, -1.5007, -0.6751]],\n",
       " \n",
       "         [[-0.7356, -0.6081, -0.5284,  ..., -0.0980, -0.0820, -0.2255],\n",
       "          [-0.7037, -0.5603, -0.5124,  ...,  0.2687,  0.4281,  0.2049],\n",
       "          [-0.6240, -0.4487, -0.4487,  ...,  1.0339,  0.9382,  0.5238],\n",
       "          ...,\n",
       "          [-0.4487, -0.4646, -0.4168,  ..., -1.1182, -0.9269, -0.2255],\n",
       "          [-0.0661, -0.1139, -0.3052,  ..., -1.1023, -1.1501, -0.3690],\n",
       "          [-0.2095, -0.4327, -0.6878,  ..., -1.1341, -1.1501, -0.3530]]]),\n",
       " <MaskLabels.MASK: 0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(data_dir, model_dir, args):\n",
    "seed_everything(42)\n",
    "\n",
    "save_dir = increment_path(os.path.join('./model/', 'exp'))\n",
    "\n",
    "# -- model\n",
    "# model_module = getattr(import_module(\"model\"), args.model)  # default: BaseModel\n",
    "# model = model_module(num_classes=num_classes).to(device)\n",
    "\n",
    "# EfficientNet 모델 불러오기 (사전 학습된 가중치 사용)\n",
    "model = timm.create_model('efficientnet_b1', pretrained=True)\n",
    "\n",
    "# 마지막 컨볼루션 레이어와 분류기를 제외한 나머지 부분 고정\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" not in name: #and \"features.7\" not in name:  # 마지막 conv 블록은 'features.7'\n",
    "        param.requires_grad = False\n",
    "\n",
    "# 새로운 분류기 정의\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_features, 3)  # 18개의 출력 레이블을 가진 새로운 분류기\n",
    "\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "# -- loss & metric\n",
    "criterion = create_criterion('cross_entropy')  # default: cross_entropy\n",
    "opt_module = getattr(import_module(\"torch.optim\"), 'SGD')  # default: SGD\n",
    "optimizer = opt_module(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-3,\n",
    "    weight_decay=5e-4,\n",
    ")\n",
    "scheduler = StepLR(optimizer, 20, gamma=0.5)\n",
    "\n",
    "# -- logging\n",
    "logger = SummaryWriter(log_dir=save_dir)\n",
    "# with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(vars(args), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/10](20/236) || training loss 1.056 || training accuracy 44.84% || lr 0.001\n",
      "Epoch[0/10](40/236) || training loss 0.8856 || training accuracy 70.47% || lr 0.001\n",
      "Epoch[0/10](60/236) || training loss 0.8126 || training accuracy 71.33% || lr 0.001\n",
      "Epoch[0/10](80/236) || training loss 0.7703 || training accuracy 72.66% || lr 0.001\n",
      "Epoch[0/10](100/236) || training loss 0.7432 || training accuracy 72.19% || lr 0.001\n",
      "Epoch[0/10](120/236) || training loss 0.7468 || training accuracy 70.86% || lr 0.001\n",
      "Epoch[0/10](140/236) || training loss 0.7013 || training accuracy 73.20% || lr 0.001\n",
      "Epoch[0/10](160/236) || training loss 0.7112 || training accuracy 72.11% || lr 0.001\n",
      "Epoch[0/10](180/236) || training loss 0.6986 || training accuracy 71.48% || lr 0.001\n",
      "Epoch[0/10](200/236) || training loss 0.6681 || training accuracy 73.12% || lr 0.001\n",
      "Epoch[0/10](220/236) || training loss 0.6983 || training accuracy 71.48% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 57.17%! saving the best model..\n",
      "[Val] acc : 57.17%, loss: 0.69 || best acc : 57.17%, best loss: 0.69\n",
      "\n",
      "Epoch[1/10](20/236) || training loss 0.6693 || training accuracy 72.34% || lr 0.001\n",
      "Epoch[1/10](40/236) || training loss 0.6709 || training accuracy 72.11% || lr 0.001\n",
      "Epoch[1/10](60/236) || training loss 0.66 || training accuracy 72.81% || lr 0.001\n",
      "Epoch[1/10](80/236) || training loss 0.6568 || training accuracy 72.66% || lr 0.001\n",
      "Epoch[1/10](100/236) || training loss 0.6402 || training accuracy 73.44% || lr 0.001\n",
      "Epoch[1/10](120/236) || training loss 0.636 || training accuracy 73.44% || lr 0.001\n",
      "Epoch[1/10](140/236) || training loss 0.6193 || training accuracy 75.47% || lr 0.001\n",
      "Epoch[1/10](160/236) || training loss 0.589 || training accuracy 77.03% || lr 0.001\n",
      "Epoch[1/10](180/236) || training loss 0.6322 || training accuracy 74.30% || lr 0.001\n",
      "Epoch[1/10](200/236) || training loss 0.5937 || training accuracy 76.80% || lr 0.001\n",
      "Epoch[1/10](220/236) || training loss 0.6308 || training accuracy 73.52% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 60.29%! saving the best model..\n",
      "[Val] acc : 60.29%, loss: 0.62 || best acc : 60.29%, best loss: 0.62\n",
      "\n",
      "Epoch[2/10](20/236) || training loss 0.5861 || training accuracy 76.95% || lr 0.001\n",
      "Epoch[2/10](40/236) || training loss 0.5907 || training accuracy 76.17% || lr 0.001\n",
      "Epoch[2/10](60/236) || training loss 0.5844 || training accuracy 76.41% || lr 0.001\n",
      "Epoch[2/10](80/236) || training loss 0.5812 || training accuracy 76.88% || lr 0.001\n",
      "Epoch[2/10](100/236) || training loss 0.5901 || training accuracy 77.42% || lr 0.001\n",
      "Epoch[2/10](120/236) || training loss 0.556 || training accuracy 79.61% || lr 0.001\n",
      "Epoch[2/10](140/236) || training loss 0.5533 || training accuracy 78.98% || lr 0.001\n",
      "Epoch[2/10](160/236) || training loss 0.5531 || training accuracy 79.77% || lr 0.001\n",
      "Epoch[2/10](180/236) || training loss 0.5446 || training accuracy 80.16% || lr 0.001\n",
      "Epoch[2/10](200/236) || training loss 0.5688 || training accuracy 77.73% || lr 0.001\n",
      "Epoch[2/10](220/236) || training loss 0.5386 || training accuracy 79.53% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 63.28%! saving the best model..\n",
      "[Val] acc : 63.28%, loss: 0.56 || best acc : 63.28%, best loss: 0.56\n",
      "\n",
      "Epoch[3/10](20/236) || training loss 0.5554 || training accuracy 78.91% || lr 0.001\n",
      "Epoch[3/10](40/236) || training loss 0.5246 || training accuracy 81.02% || lr 0.001\n",
      "Epoch[3/10](60/236) || training loss 0.5411 || training accuracy 79.92% || lr 0.001\n",
      "Epoch[3/10](80/236) || training loss 0.53 || training accuracy 81.09% || lr 0.001\n",
      "Epoch[3/10](100/236) || training loss 0.5264 || training accuracy 81.33% || lr 0.001\n",
      "Epoch[3/10](120/236) || training loss 0.5266 || training accuracy 79.69% || lr 0.001\n",
      "Epoch[3/10](140/236) || training loss 0.5031 || training accuracy 82.42% || lr 0.001\n",
      "Epoch[3/10](160/236) || training loss 0.5211 || training accuracy 80.70% || lr 0.001\n",
      "Epoch[3/10](180/236) || training loss 0.4934 || training accuracy 82.42% || lr 0.001\n",
      "Epoch[3/10](200/236) || training loss 0.4769 || training accuracy 84.45% || lr 0.001\n",
      "Epoch[3/10](220/236) || training loss 0.501 || training accuracy 81.88% || lr 0.001\n",
      "Calculating validation results...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m outs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     55\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m loss_item \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m acc_item \u001b[38;5;241m=\u001b[39m (labels \u001b[38;5;241m==\u001b[39m preds)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     59\u001b[0m val_loss_items\u001b[38;5;241m.\u001b[39mappend(loss_item)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % 20 == 0:\n",
    "            train_loss = loss_value / 20\n",
    "            train_acc = matches / 64 / 20\n",
    "            current_lr = get_lr(optimizer)\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{10}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "            )\n",
    "            logger.add_scalar(\n",
    "                \"Train/loss\", train_loss, epoch * len(train_loader) + idx\n",
    "            )\n",
    "            logger.add_scalar(\n",
    "                \"Train/accuracy\", train_acc, epoch * len(train_loader) + idx\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        figure = None\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "\n",
    "            if figure is None:\n",
    "                inputs_np = (\n",
    "                    torch.clone(inputs).detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "                )\n",
    "                inputs_np = dataset_module.denormalize_image(\n",
    "                    inputs_np, dataset.mean, dataset.std\n",
    "                )\n",
    "                figure = grid_image(\n",
    "                    inputs_np,\n",
    "                    labels,\n",
    "                    preds,\n",
    "                    n=16,\n",
    "                    shuffle=MaskBaseDataset != \"MaskSplitByProfileDataset\",\n",
    "                )\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_set)\n",
    "        best_val_loss = min(best_val_loss, val_loss)\n",
    "        if val_acc > best_val_acc:\n",
    "            print(\n",
    "                f\"New best model for val accuracy : {val_acc:4.2%}! saving the best model..\"\n",
    "            )\n",
    "            torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "            best_val_acc = val_acc\n",
    "        torch.save(model.module.state_dict(), f\"{save_dir}/last.pth\")\n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )\n",
    "        logger.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "        logger.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "        logger.add_figure(\"results\", figure, epoch)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
